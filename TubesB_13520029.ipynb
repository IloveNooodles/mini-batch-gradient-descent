{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFmg9hFG70Uq"
   },
   "source": [
    "<h1><b>Tubes B</b></h1>\n",
    "<h4>Implementasi Backpropagation</h4>\n",
    "\n",
    "Anggota Kelompok:\n",
    "- 13520001 - Fayza Nadia\n",
    "- 13520014 - Muhammad Helmi Hibatullah\n",
    "- 13520026 - Muhammad Fajar Ramadhan\n",
    "- 13520029 - Muhammad Garebaldhie Er Rahman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model yang dibuat menggunakan format seperti berikut\n",
    "\n",
    "file `sigmoid.json`\n",
    "```json\n",
    "{\n",
    "  \"case\": {\n",
    "    \"model\": {\n",
    "      \"input_size\": 2,\n",
    "      \"layers\": [\n",
    "        {\n",
    "          \"number_of_neurons\": 3,\n",
    "          \"activation_function\": \"sigmoid\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"input\": [\n",
    "      [0.0, 0.0],\n",
    "      [0.0, 0.1]\n",
    "    ],\n",
    "    \"initial_weights\": [\n",
    "      [\n",
    "        [0.1, 0.2, 0.3],\n",
    "        [0.4, 0.5, 0.6],\n",
    "        [0.9, 0.1, 0.2]\n",
    "      ]\n",
    "    ],\n",
    "    \"target\": [\n",
    "      [0.1, 1.0],\n",
    "      [1.0, 0.0]\n",
    "    ],\n",
    "    \"learning_parameters\": {\n",
    "      \"learning_rate\": 0.1,\n",
    "      \"batch_size\": 2,\n",
    "      \"max_iteration\": 1,\n",
    "      \"error_threshold\": 0.1\n",
    "    }\n",
    "  },\n",
    "  \"expect\": {\n",
    "    \"stopped_by\": \"max_iteration\",\n",
    "    \"final_weights\": [\n",
    "      [\n",
    "        [0.1, 2.86, 0.17],\n",
    "        [0.5, -2.46, 0.41],\n",
    "        [0.9, 0.0, -1.76]\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "1. `model`: Terdiri dari ukuran input yang diterima dan input layer yang berisi jumlah neuron serta fungsi aktivasi (linear, relu, sigmoid, softmax).\n",
    "\n",
    "2. `input`: Menyatakan input yang terdiri dari 2 dimensi.\n",
    "- dimensi 1 merupakan vektor ke-i.\n",
    "- dimensi 2 merupakan isi suatu vektor.\n",
    "\n",
    "3. `initial_weights`: Menyatakan inisiasi bobot pada awal.\n",
    "- dimensi 1 bersesuaian dengan layers\n",
    "- dimensi 2 berukuran banyak neuron pada layer sebelumnya + 1 dengan layer pertama adalah ukuran input + 1 serta baris pertama merupakan bias.\n",
    "- dimensi 3 berukuran banyak neuron pada layer yang bersesuaian.\n",
    "\n",
    "4. `target`: Menyatakan hasil output dari backpropagation.\n",
    "- dimensi 1 berukuran sama dengan dimensi 1 pada input.\n",
    "- dimensi 2 berukuran sama dengan banyak neuron pada layer terakhir.\n",
    "\n",
    "5. `learning_parameters`: Parameter yang terdiri dari learning rate, batch size, max iteration, dan error threshold.\n",
    "\n",
    "6. `stopped_by`: Berisi 2 nilai valid, yaitu max iteration atau error threshold, sebagai penentu terminasi.\n",
    "\n",
    "7. `final_weights`: Bobot akhir yang digunakan untuk pengecekan setelah seluruh iterasi dijalankan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python\\lib\\site-packages (1.23.2)\n",
      "Requirement already satisfied: pandas in c:\\python\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: graphviz in c:\\python\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\python\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\lib\\site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\python\\lib\\site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 23.1.2\n",
      "[notice] To update, run: c:\\python\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas graphviz scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPRZ_Jhf70Us"
   },
   "source": [
    "<h3><b>Class & Function</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTndzbIg70Us"
   },
   "source": [
    "<b>Import</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TTGVBo6e70Us"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from graphviz import Digraph\n",
    "from typing import List, Dict\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import (GridSearchCV, cross_validate,\n",
    "                                     train_test_split)\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwD39npi70Ut"
   },
   "source": [
    "<b>Activation</b>\n",
    "\n",
    "Class Activation adalah kelas yang berisi fungsi-fungsi aktivasi yang digunakan pada neural network. Fungsi-fungsi tersebut adalah linear, relu, sigmoid, dan softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "csA8_AtN70Ut"
   },
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    LINEAR = \"linear\"\n",
    "    RELU = \"relu\"\n",
    "    SIGMOID = \"sigmoid\"\n",
    "    SOFTMAX = \"softmax\"\n",
    "\n",
    "    def __init__(self, mode) -> None:\n",
    "        self.mode = mode\n",
    "\n",
    "    def __linear_calculate(self, res):\n",
    "        return res\n",
    "\n",
    "    def __linear_derivative(self, res):\n",
    "        return np.ones(np.shape(res))\n",
    "\n",
    "    def __sigmoid_calculate(self, res):\n",
    "        res = np.array([(1 / (1 + pow(math.e, -x))) for x in res])\n",
    "        return res\n",
    "\n",
    "    def __sigmoid_derivative(self, res):\n",
    "        return res * (1 - res)\n",
    "\n",
    "    def __relu_calculate(self, res):\n",
    "        res[res < 0] = 0\n",
    "        return res\n",
    "\n",
    "    def __relu_derivative(self, res):\n",
    "        res[res <= 0] = 0\n",
    "        res[res > 0] = 1\n",
    "        return res\n",
    "\n",
    "    def __softmax_calculate(self, res):\n",
    "        numerator = np.array([pow(math.e, x) for x in res])\n",
    "        denominator = np.array([np.sum(pow(math.e, x)) for x in res])\n",
    "        result = np.empty(numerator.shape)\n",
    "\n",
    "        for index, ele in enumerate(numerator):\n",
    "            result[index] = ele / denominator[index]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __softmax_derivative(self, res, target=[]):\n",
    "        \"\"\" \n",
    "        if t == 1 then -(1-o) -> o - 1\n",
    "        \"\"\"\n",
    "        subtract = np.subtract(res, target)\n",
    "        return np.array(subtract)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def calculate(self, x, w, b):\n",
    "        res = np.matmul(x, w)\n",
    "        res = np.add(res, b)\n",
    "        if self.mode == Activation.LINEAR:\n",
    "            return self.__linear_calculate(res)\n",
    "        elif self.mode == Activation.RELU:\n",
    "            return self.__relu_calculate(res)\n",
    "        elif self.mode == Activation.SIGMOID:\n",
    "            return self.__sigmoid_calculate(res)\n",
    "        elif self.mode == Activation.SOFTMAX:\n",
    "            return self.__softmax_calculate(res)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Mode is not implemented, please select correct mode\")\n",
    "\n",
    "    def derivative(self, res, target=[]):\n",
    "        if self.mode == Activation.LINEAR:\n",
    "            return self.__linear_derivative(res)\n",
    "        elif self.mode == Activation.RELU:\n",
    "            return self.__relu_derivative(res)\n",
    "        elif self.mode == Activation.SIGMOID:\n",
    "            return self.__sigmoid_derivative(res)\n",
    "        elif self.mode == Activation.SOFTMAX:\n",
    "            return self.__softmax_derivative(res, target)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Mode is not implemented, please select correct mode\")\n",
    "\n",
    "    def predict(self, res):\n",
    "        if self.mode == Activation.LINEAR:\n",
    "            return res\n",
    "        elif self.mode == Activation.RELU:\n",
    "            return res\n",
    "        elif self.mode == Activation.SIGMOID:\n",
    "            return res\n",
    "        elif self.mode == Activation.SOFTMAX:\n",
    "            return res\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Mode is not implemented, please select correct mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4XHLZS270Uu"
   },
   "source": [
    "<b>Reader</b>\n",
    "\n",
    "Class Reader adalah kelas yang berfungsi untuk membaca berkas json yang berisi model FFNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fNM8KP0e70Uu"
   },
   "outputs": [],
   "source": [
    "ACTIVATION_LIST = [Activation.LINEAR, Activation.RELU,\n",
    "                   Activation.SIGMOID, Activation.SOFTMAX]\n",
    "\n",
    "MAX_SSE = 1e-8\n",
    "BASE_FFNN_PATH = \"test/test_case_ffnn/\"\n",
    "BASE_BACKPROP_PATH = \"test/test_case_backprop/\"\n",
    "\n",
    "\n",
    "class Reader:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def read_ffnn(filename: str) -> Dict:\n",
    "        \"\"\" \n",
    "        Read ffnn models from json\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(BASE_FFNN_PATH + filename, \"rb\") as f:\n",
    "                json_file = json.load(f)\n",
    "                # Return models\n",
    "                if validate_data(json_file):\n",
    "                    return json_file\n",
    "                return None\n",
    "        except OSError as e:\n",
    "            print(\"File not found\")\n",
    "            os._exit(-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_backprop(filename: str) -> Dict:\n",
    "        \"\"\" \n",
    "        Read json file for backprogation test case\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(BASE_BACKPROP_PATH + filename, \"rb\") as f:\n",
    "                json_file = json.load(f)\n",
    "                raw_model = json_file[\"case\"]\n",
    "                transformed_model = transform_to_ffnn_model(raw_model)\n",
    "                expected = json_file[\"expect\"]\n",
    "\n",
    "                return raw_model, transformed_model, expected\n",
    "\n",
    "        except OSError as e:\n",
    "            print(\"File not found\")\n",
    "            os._exit(-1)\n",
    "\n",
    "\n",
    "def transform_to_ffnn_model(input_model: dict):\n",
    "    \"\"\" \n",
    "    Needed to trasnsform to the current FFNN model\n",
    "    \"\"\"\n",
    "    model = {}\n",
    "    model[\"layers\"] = len(input_model[\"model\"][\"layers\"]) + 1\n",
    "    model[\"activation_functions\"] = [x[\"activation_function\"]\n",
    "                                     for x in input_model[\"model\"][\"layers\"]]\n",
    "    model[\"neurons\"] = [input_model[\"model\"][\"input_size\"]] + [x[\"number_of_neurons\"]\n",
    "                                                               for x in input_model[\"model\"][\"layers\"]]\n",
    "    model[\"weights\"] = [np.transpose(x)\n",
    "                        for x in input_model[\"initial_weights\"]]\n",
    "    model[\"rows\"] = len(input_model[\"input\"])\n",
    "    model[\"data\"] = input_model[\"input\"]\n",
    "    model[\"target\"] = input_model[\"target\"]\n",
    "    model[\"max_sse\"] = MAX_SSE\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def validate_data(json_data) -> bool:\n",
    "    \"\"\" \n",
    "    Validate input data .json\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate layers\n",
    "    layers = json_data['layers']\n",
    "    activation_functions = np.array(\n",
    "        json_data['activation_functions'], dtype=np.string_)\n",
    "\n",
    "    # Neurons are input hidden output\n",
    "    neurons = np.array(json_data['neurons'], dtype=np.int32)\n",
    "    weights = json_data['weights']\n",
    "    rows = json_data['rows']\n",
    "    data = np.array(json_data['data'], dtype=np.float64)\n",
    "    data_names = np.array(json_data['data_names'], dtype=np.string_)\n",
    "    target_names = np.array(json_data['target_names'], dtype=np.string_)\n",
    "    target = np.array(json_data['target'], dtype=np.int32)\n",
    "    max_sse = json_data['max_sse']\n",
    "\n",
    "    if not isinstance(layers, int):\n",
    "        raise Exception(\"Layers is not integer\")\n",
    "\n",
    "    # Validate activation function per layers\n",
    "    if activation_functions.shape[0] != layers - 1:\n",
    "        raise Exception(\"Length of activation functions is not the same\")\n",
    "\n",
    "    for function in activation_functions:\n",
    "        if function.decode() not in ACTIVATION_LIST:\n",
    "            raise Exception(\"Invalid activation functions\")\n",
    "\n",
    "    # # Validate neurons\n",
    "    if neurons.shape[0] != layers:\n",
    "        raise Exception(\"Neurons number don't match with layers\")\n",
    "\n",
    "    assert neurons.dtype == np.int32\n",
    "\n",
    "    # Validate weights, weights must be layers - 1\n",
    "    if len(weights) != layers - 1:\n",
    "        raise Exception(\"Please input correct weights\")\n",
    "\n",
    "    for index, weight_per_neuron in enumerate(weights):\n",
    "        for weight_neuron in weight_per_neuron:\n",
    "            if len(weight_neuron) != neurons[index] + 1:\n",
    "                raise Exception(\n",
    "                    f\"Invalid number of weights parameter in weight {index}\")\n",
    "            np.array(weight_neuron, dtype=np.float64)\n",
    "\n",
    "    # Validate rows\n",
    "    if not isinstance(rows, int):\n",
    "        raise Exception(\"Rows is not integer\")\n",
    "\n",
    "    # data_names\n",
    "    len_data_features = data_names.shape[0]\n",
    "    assert np.issubdtype(data_names.dtype, np.string_) == True\n",
    "\n",
    "    # data attr\n",
    "    if data.shape[0] != rows:\n",
    "        raise Exception(\"Number of data doesn't match with rows\")\n",
    "\n",
    "    if data.shape[1] != len_data_features:\n",
    "        raise Exception(\"Number of data columns doesnt match\")\n",
    "\n",
    "    assert np.issubdtype(target_names.dtype, np.string_) == True\n",
    "    assert target.shape[0] == rows\n",
    "\n",
    "    if not isinstance(max_sse, float):\n",
    "        raise Exception(\"Please input correct sse\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGSM1RKq70Uv"
   },
   "source": [
    "<b>FFNN Algorithm</b>\n",
    "\n",
    "Class FFNN adalah kelas yang berfungsi untuk mengimplementasikan algoritma forward propagation pada FFNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kujSFF_970Uv"
   },
   "outputs": [],
   "source": [
    "class FFNN:\n",
    "    def __init__(self, model) -> None:\n",
    "        self.layers = model['layers']\n",
    "        self.activation_functions = np.array(model['activation_functions'])\n",
    "        self.neurons = np.array(model['neurons'])\n",
    "        self.weights = model['weights']\n",
    "        self.data = np.array(model['data'])\n",
    "        self.target = np.array(model['target'])\n",
    "        self.output = None\n",
    "        self.ouput_per_layer = []\n",
    "        self.max_sse = model[\"max_sse\"]\n",
    "        pass\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"\\\n",
    "  Layers: {self.layers}\\n\\\n",
    "  Activations: {self.activation_functions}\\n\\\n",
    "  Neurons: {self.neurons}\\n\\\n",
    "  Weights: {self.weights}\\n\\\n",
    "  Data: {self.data}\\n\\\n",
    "  target: {self.target}\\n\\\n",
    "  max_sse: {self.max_sse}\\n\"\n",
    "\n",
    "    # Will return output functions\n",
    "    def compute(self):\n",
    "        res = self.data\n",
    "        for i in range(self.layers - 1):\n",
    "            activation_function = Activation(\n",
    "                self.activation_functions[i])\n",
    "            transposed_weights = np.transpose(np.array(self.weights[i]))\n",
    "            weights, bias = self.separate_bias(transposed_weights)\n",
    "            res = activation_function.calculate(res, weights, bias)\n",
    "            self.ouput_per_layer.append(res)\n",
    "        self.output = res\n",
    "        return res\n",
    "\n",
    "    def get_all_output_layer(self):\n",
    "        return self.ouput_per_layer\n",
    "\n",
    "    def separate_bias(self, data):\n",
    "        bias = data[0, :]\n",
    "        weight = data[1:, :]\n",
    "        return weight, bias\n",
    "\n",
    "    def predict(self):\n",
    "        A = Activation(self.activation_functions[-1])\n",
    "        res = A.predict(self.output)\n",
    "        sse = self._calculate_sse()\n",
    "        print(f\"\\\n",
    "  Data: {self.data}\\n\\\n",
    "  Target: {self.target}\\n\\\n",
    "  Predictions: {res}\\n\\\n",
    "  SSE: {sse}\\n\\\n",
    "  isValid: {[s < self.max_sse for s in sse]} ( < {self.max_sse})\\n\")\n",
    "\n",
    "    def _calculate_sse(self):\n",
    "        sse = 0\n",
    "        for i in range(len(self.output)):\n",
    "            sse += pow(self.output[i] - self.target[i], 2)\n",
    "        sse = sse / 2\n",
    "        return sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BAuW-l270Uv"
   },
   "source": [
    "<b>Graph</b>\n",
    "\n",
    "Class Graph adalah kelas yang berfungsi untuk menggambar grafik dari hasil forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A-av2U2170Uw"
   },
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, ffnn: FFNN, filename: str) -> None:\n",
    "        self.ffnn = ffnn\n",
    "        self.filename = filename\n",
    "        self.f = Digraph(\n",
    "            'G', filename=f'./res/{self.filename}_graph', format='png')\n",
    "\n",
    "    def draw(self):\n",
    "        self.f.attr('node', shape='circle')\n",
    "        self._add_node()\n",
    "        self._add_edge()\n",
    "        self.f.view()\n",
    "        return self.f\n",
    "\n",
    "    def _add_node(self):\n",
    "        # Add input nodes\n",
    "        self.f.node(\"b1\")\n",
    "        # Pake data aja\n",
    "        for index, data_name in enumerate(self.ffnn.data[0]):\n",
    "            self.f.node(f\"x{index}\")\n",
    "\n",
    "        # Add nodes in the next layers\n",
    "        for layer in range(1, self.ffnn.layers - 1):\n",
    "            self.f.node(f\"b{layer+1}\")\n",
    "            for j in range(self.ffnn.neurons[layer]):\n",
    "                self.f.node(f\"h{layer}{j+1}\")\n",
    "\n",
    "    def _add_edge(self):\n",
    "        # Add edges between layers\n",
    "        layers = self.ffnn.layers\n",
    "\n",
    "        for layer in range(layers - 1):\n",
    "            transposed_weights = np.transpose(\n",
    "                np.array(self.ffnn.weights[layer]))\n",
    "            weights, bias = self.ffnn.separate_bias(transposed_weights)\n",
    "\n",
    "            # Add edges between bias and hidden layer or output\n",
    "            for i in range(len(bias)):\n",
    "                if layers == 2:\n",
    "                    bias_name = f\"b{layer+1}\"\n",
    "                    end = f\"y{i+1}\"\n",
    "                else:\n",
    "                    bias_name = f\"b{layer+1}\"\n",
    "                    end = f\"h{layer+1}{i+1}\"\n",
    "                    if layer == self.ffnn.layers - 2:\n",
    "                        end = f\"y{i+1}\"\n",
    "\n",
    "                self.f.edge(bias_name, end, label=f\"{bias[i]}\")\n",
    "\n",
    "            # Add edges between input and hidden layer or output\n",
    "            for i in range(self.ffnn.neurons[layer]):\n",
    "                for j in range(len(weights[i])):\n",
    "                    if layers == 2:\n",
    "                        start = str(f\"x{i}\")\n",
    "                        end = f\"y{j+1}\"\n",
    "                    elif layer == 0:\n",
    "                        start = str(f\"x{i}\")\n",
    "                        end = f\"h{layer+1}{j+1}\"\n",
    "                    elif layer == self.ffnn.layers - 2:\n",
    "                        start = f\"h{layer}{i+1}\"\n",
    "                        end = f\"y{j+1}\"\n",
    "                    else:\n",
    "                        start = f\"h{layer}{i+1}\"\n",
    "                        end = f\"h{layer+1}{j+1}\"\n",
    "                    self.f.edge(start, end, label=f\"{weights[i][j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop\n",
    "Backpropgation implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SSE = 1e-8\n",
    "\n",
    "\n",
    "class Backpropagation:\n",
    "    def __init__(self, model, expected, ffnn_model) -> None:\n",
    "        self.input_size = model[\"model\"][\"input_size\"]\n",
    "        self.layers = model[\"model\"][\"layers\"]\n",
    "        self.input = np.array(model[\"input\"])\n",
    "        self.weights = np.array(model[\"initial_weights\"])\n",
    "        self.target = np.array(model[\"target\"])\n",
    "        self.learning_rate = model[\"learning_parameters\"][\"learning_rate\"]\n",
    "        self.batch_size = model[\"learning_parameters\"][\"batch_size\"]\n",
    "        self.max_iteration = model[\"learning_parameters\"][\"max_iteration\"]\n",
    "        self.error_threshold = model[\"learning_parameters\"][\"error_threshold\"]\n",
    "        self.expected = expected\n",
    "        self.ffnn_model = ffnn_model\n",
    "        self.single_output = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        \"\"\" \n",
    "        Propagate Forward using FFNN\n",
    "        \"\"\"\n",
    "        ffnn = FFNN(self.ffnn_model)\n",
    "        res = ffnn.compute()\n",
    "        self.single_output = res\n",
    "        self.output = np.array(ffnn.get_all_output_layer())\n",
    "\n",
    "    def back_propagate(self):\n",
    "        \"\"\" \n",
    "        epoch: banyaknya iterasi pada setiap \n",
    "\n",
    "        batch_size paramater ukuran minibatch utk Stochastic gradient descent\n",
    "\n",
    "        step: pemrosesan satu minibatch\n",
    "\n",
    "        \"\"\"\n",
    "        total_batch = self.split_input_targets_to_batch(\n",
    "            self.input, self.target, self.batch_size)\n",
    "\n",
    "        epoch = 0\n",
    "\n",
    "        self.forward_propagation()\n",
    "        current_epoch_error = self.__loss(\n",
    "            self.target, self.single_output, self.layers[-1][\"activation_function\"])\n",
    "\n",
    "        print(\"=\"*6 + \" Backpropagation start \" + \"=\"*6)\n",
    "        # Selama belum gg, backpropagate , update bobot trs feed lagi kedepan\n",
    "        while (epoch < self.max_iteration and current_epoch_error >= self.error_threshold):\n",
    "            total_layer = len(self.layers)\n",
    "            prev_error = None\n",
    "            print(\"=\" * 8 + f\" EPOCH {epoch + 1} \" + \"=\" * 8)\n",
    "            print(f\"ERROR: {current_epoch_error}\")\n",
    "            print(f\"Output: {self.single_output}\")\n",
    "            for index_layer in range(total_layer - 1, -1, -1):\n",
    "                current_activation = self.layers[index_layer][\"activation_function\"]\n",
    "                output_layer = self.output[index_layer]\n",
    "                a = Activation(current_activation)\n",
    "                for index, batch_instance in enumerate(total_batch):\n",
    "                    inputs = np.array(batch_instance[\"inputs\"])\n",
    "                    targets = np.array(batch_instance[\"targets\"])\n",
    "                    gradient = None\n",
    "\n",
    "                    delta_weights = np.zeros(self.weights[index_layer].shape)\n",
    "                    # Kalau dia punya output (layer paling ujung)\n",
    "                    for instance_index, instance in enumerate(inputs):\n",
    "                        if index_layer == total_layer - 1:\n",
    "                            # Calculate dho error / dho weight\n",
    "                            # First part: -(t - o) -> (o - t)\n",
    "                            first_part = np.subtract(\n",
    "                                output_layer[instance_index], targets[instance_index])\n",
    "\n",
    "                            # Second part: derivative\n",
    "                            second_part = a.derivative(\n",
    "                                output_layer[instance_index], targets[instance_index])\n",
    "\n",
    "                            # Third part: input di layer sebelumnya\n",
    "                            third_part = None\n",
    "\n",
    "                            # Kalau cuma 1 layer, pake input layer\n",
    "                            # add bias\n",
    "                            if len(self.output) == 1:\n",
    "                                third_part = np.ones(\n",
    "                                    instance.shape[0] + 1)\n",
    "                                third_part[1:] = instance\n",
    "                            else:\n",
    "                                shape = self.output[index_layer -\n",
    "                                                    1][instance_index].shape\n",
    "                                third_part = np.ones(shape[0] + 1)\n",
    "                                third_part[1:] = self.output[index_layer -\n",
    "                                                             1][instance_index]\n",
    "                            # Third part must same as len each inital weights transposed\n",
    "                            cur_weights = np.transpose(\n",
    "                                self.weights[index_layer])\n",
    "                            third_parts = np.zeros(cur_weights.shape)\n",
    "\n",
    "                            for i in range(len(cur_weights)):\n",
    "                                third_parts[i] = third_part\n",
    "\n",
    "                            third_parts = np.transpose(third_parts)\n",
    "\n",
    "                            if current_activation == Activation.SOFTMAX:\n",
    "                                prev_error = second_part\n",
    "                            else:\n",
    "                                prev_error = np.multiply(\n",
    "                                    first_part, second_part)\n",
    "                            gradient = np.multiply(prev_error, third_parts)\n",
    "\n",
    "                        # Kalau hidden layer\n",
    "                        else:\n",
    "                            # Calculate dho error / dho weight\n",
    "                            # First part: dho error / dho net\n",
    "\n",
    "                            # dho Ed / dho net_o; prev error\n",
    "                            # print(prev_error)\n",
    "                            # dho net_o / dho h\n",
    "                            # remove bias\n",
    "                            next_layer_cur_weights = self.weights[index_layer + 1][1:]\n",
    "                            # print(next_layer_cur_weights)\n",
    "\n",
    "                            # dho Ed / dho h\n",
    "                            temp = np.multiply(\n",
    "                                prev_error, next_layer_cur_weights)\n",
    "\n",
    "                            # calculate sum of the error outputs layer\n",
    "                            output_layer_sum_error = np.array(\n",
    "                                [np.sum(x) for x in temp])\n",
    "                            derivative = a.derivative(\n",
    "                                output_layer[instance_index], targets[instance_index])\n",
    "\n",
    "                            # calculate prev error\n",
    "                            prev_error = np.multiply(\n",
    "                                output_layer_sum_error, derivative)\n",
    "\n",
    "                            # Second part: dho net / dho weight\n",
    "                            second_part = None\n",
    "\n",
    "                            # Kalau udah paling ujung\n",
    "                            if index_layer == 0:\n",
    "                                second_part = np.ones(instance.shape[0] + 1)\n",
    "                                second_part[1:] = instance\n",
    "                            else:\n",
    "                                shape = self.output[index_layer][instance_index].shape\n",
    "                                second_part = np.ones(shape[0] + 1)\n",
    "                                second_part[1:] = self.output[index_layer][instance_index]\n",
    "\n",
    "                            cur_weights = np.transpose(self.weights[i])\n",
    "                            second_parts = np.zeros(cur_weights.shape)\n",
    "                            for i in range(len(cur_weights)):\n",
    "                                second_parts[i] = second_part\n",
    "\n",
    "                            second_parts = np.transpose(second_parts)\n",
    "                            gradient = np.multiply(prev_error, second_parts)\n",
    "                            # print(gradient)\n",
    "\n",
    "                        # Update delta weights\n",
    "                        delta_weights = delta_weights - \\\n",
    "                            np.dot(self.learning_rate, gradient)\n",
    "\n",
    "                    # Update weight\n",
    "                    print(\"DELTA WEGIHTS CUY\", delta_weights)\n",
    "                    self.weights[index_layer] = self.weights[index_layer] + \\\n",
    "                        delta_weights\n",
    "                    print(\n",
    "                        f\"Layer {index_layer + 1} Batch {index + 1} completed\")\n",
    "\n",
    "            new_weights = [np.transpose(x) for x in self.weights]\n",
    "            self.ffnn_model[\"weights\"] = new_weights\n",
    "            self.forward_propagation()\n",
    "            current_epoch_error = self.__loss(\n",
    "                self.target,  self.single_output, self.layers[-1][\"activation_function\"])\n",
    "\n",
    "            epoch += 1\n",
    "\n",
    "        print(\"Backpropagation complete\")\n",
    "        if current_epoch_error < self.error_threshold:\n",
    "            print(\n",
    "                f\"Reason: error ({current_epoch_error}) < threshold ({self.error_threshold})\")\n",
    "        else:\n",
    "            print(\"Reason: Max iteration reached\")\n",
    "\n",
    "        print(\"Final output\")\n",
    "        print(self.single_output)\n",
    "        print(\"Final weights\")\n",
    "        print(self.weights)\n",
    "        print(\"Excpected\")\n",
    "        print(np.array(self.expected[\"final_weights\"]))\n",
    "\n",
    "    def split_input_targets_to_batch(self, inputs: List, targets: List, batch_size: int) -> List[List]:\n",
    "        \"\"\" \n",
    "        Split input and targets into batch\n",
    "        \"\"\"\n",
    "\n",
    "        total_batch = []\n",
    "        ctr = 0\n",
    "        cur_input = []\n",
    "        cur_target = []\n",
    "\n",
    "        length = len(inputs)\n",
    "        for i in range(length):\n",
    "            cur_target.append(targets[i])\n",
    "            cur_input.append(inputs[i])\n",
    "\n",
    "            ctr += 1\n",
    "\n",
    "            if ctr == batch_size:\n",
    "                total_batch.append({\n",
    "                    \"inputs\": cur_input,\n",
    "                    \"targets\": cur_target\n",
    "                })\n",
    "\n",
    "                ctr = 0\n",
    "                cur_target = []\n",
    "                cur_input = []\n",
    "\n",
    "        return total_batch\n",
    "\n",
    "    def __loss(self, target, pred, activation):\n",
    "        \"\"\" \n",
    "        For linear, sigmoid, relu use SSE.\n",
    "\n",
    "        Softmax use cross entropy \n",
    "        \"\"\"\n",
    "        if activation == Activation.SOFTMAX:\n",
    "            return self.__cross_entropy(target, pred)\n",
    "        else:\n",
    "            return self.__sse(target, pred)\n",
    "\n",
    "    def __sse(self, target, pred):\n",
    "        \"\"\" \n",
    "        Calculate errors using sse\n",
    "\n",
    "        sum squared of (target - pred )/ 2\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        length = len(pred)\n",
    "        for i in range(length):\n",
    "            total += pow(target[i] - pred[i], 2)\n",
    "        return np.sum(total) / 2\n",
    "\n",
    "    def __cross_entropy(self, target, pred):\n",
    "        \"\"\" \n",
    "        Calculate cross entropy\n",
    "\n",
    "        If target == 1 then -np log pj\n",
    "\n",
    "        \"\"\"\n",
    "        res = 0\n",
    "        for index, val in enumerate(target):\n",
    "            for j, t in enumerate(val):\n",
    "                if t == 1:\n",
    "                    res += np.sum(-np.log(pred[index][j]))\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhG2G3xB70Uw"
   },
   "source": [
    "<h3><b>Main Program</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guLieLXS70Uw",
    "outputId": "c0156af5-0122-425e-c8a6-69e2b99b7f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "                Backpropagation              \n",
      "=============================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input filename inside test folder:  linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Backpropagation start ======\n",
      "======== EPOCH 1 ========\n",
      "ERROR: 0.6649999999999999\n",
      "Output: [[ 1.4  0.1 -1.4]\n",
      " [ 0.7 -1.1  0.5]]\n",
      "DELTA WEGIHTS CUY [[ 0.12  0.06 -0.09]\n",
      " [ 0.24  0.1  -0.19]\n",
      " [ 0.18  0.1  -0.13]]\n",
      "Layer 1 Batch 1 completed\n",
      "Backpropagation complete\n",
      "Reason: Max iteration reached\n",
      "Final output\n",
      "[[ 2.42  0.56 -2.19]\n",
      " [ 1.42 -0.74 -0.04]]\n",
      "Final weights\n",
      "[[[ 0.22  0.36  0.11]\n",
      "  [ 0.64  0.3  -0.89]\n",
      "  [ 0.28 -0.7   0.37]]]\n",
      "Excpected\n",
      "[[[ 0.22  0.36  0.11]\n",
      "  [ 0.64  0.3  -0.89]\n",
      "  [ 0.28 -0.7   0.37]]]\n",
      "=============================================\n",
      "Graph is saved in folder res with name: linear_graph.png\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"=============================================\")\n",
    "    print(\"                Backpropagation              \")\n",
    "    print(\"=============================================\")\n",
    "    filename = input(\"Input filename inside test folder: \")\n",
    "\n",
    "    # path = \"./test/\"\n",
    "    # transformed_model = Reader.read_ffnn(\"softmax.json\")\n",
    "    raw_model, ffnn_model, expected = Reader.read_backprop(\n",
    "        \"linear.json\")  # Ganti ke file\n",
    "\n",
    "    b = Backpropagation(raw_model, expected, ffnn_model)\n",
    "    b.back_propagate()\n",
    "\n",
    "    ffnn = FFNN(model=ffnn_model)\n",
    "    filename = filename.split(\".\")[0]\n",
    "    graph = Graph(ffnn, filename)\n",
    "\n",
    "    print(\"=============================================\")\n",
    "    print(\"Graph is saved in folder res with name: \" +\n",
    "          filename + \"_graph.png\")\n",
    "    print(\"=============================================\")\n",
    "    graph.draw()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e31aef8222fb7c235d2ed8e74ce17e973738f89b37261e7466b7a63a6dfb1214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
